{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":81704,"databundleVersionId":8996362,"sourceType":"competition"},{"sourceId":83787,"databundleVersionId":9346566,"sourceType":"competition"},{"sourceId":1323925,"sourceType":"datasetVersion","datasetId":767903},{"sourceId":3951115,"sourceType":"datasetVersion","datasetId":1027206},{"sourceId":8847660,"sourceType":"datasetVersion","datasetId":5325404},{"sourceId":9196142,"sourceType":"datasetVersion","datasetId":5559552},{"sourceId":89885,"sourceType":"modelInstanceVersion","modelInstanceId":75378,"modelId":100104}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wc -l /kaggle/input/deepfake/phase1/trainset_label.txt\n!wc -l /kaggle/input/deepfake/phase1/valset_label.txt\n!ls /kaggle/input/deepfake/phase1/trainset/ | wc -l \n!ls /kaggle/input/deepfake/phase1/valset/ | wc -l ","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:52:57.260358Z","iopub.execute_input":"2024-08-15T10:52:57.260807Z","iopub.status.idle":"2024-08-15T10:53:09.270000Z","shell.execute_reply.started":"2024-08-15T10:52:57.260770Z","shell.execute_reply":"2024-08-15T10:53:09.268957Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"524430 /kaggle/input/deepfake/phase1/trainset_label.txt\n147364 /kaggle/input/deepfake/phase1/valset_label.txt\n524429\n147363\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install timm\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.272236Z","iopub.execute_input":"2024-08-15T10:53:09.273085Z","iopub.status.idle":"2024-08-15T10:53:09.281069Z","shell.execute_reply.started":"2024-08-15T10:53:09.273045Z","shell.execute_reply":"2024-08-15T10:53:09.279145Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[2], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    curl 'http://zoloz-open.oss-cn-hangzhou.aliyuncs.com/waitan2024_deepfake_challenge%2F_%E8%B5%9B%E9%81%931%E5%AF%B9%E5%A4%96%E5%8F%91%E5%B8%83%E6%95%B0%E6%8D%AE%E9%9B%86%2Fphase2_images.tar.gz?Expires=1725450713&OSSAccessKeyId=LTAI5tAfcZDV5eCa1BBEJL9R&Signature=RWPqq1L2QE8gfRDXT4IigpoDKq0%3D' -o multiFFDI-phase2.tar.gz\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (680583204.py, line 2)","output_type":"error"}]},{"cell_type":"code","source":"import torch\ntorch.manual_seed(3407)\ntorch.cuda.manual_seed(3407)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import DualTransform, ImageOnlyTransform\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\nimport timm\nimport time\nimport os\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom PIL import Image\nfrom tqdm import tqdm_notebook\n\ntrain_label = pd.read_csv('/kaggle/input/deepfake/phase1/trainset_label.txt')\nval_label = pd.read_csv('/kaggle/input/deepfake/phase1/valset_label.txt')\n\ntrain_label['path'] = '/kaggle/input/deepfake/phase1/trainset/' + train_label['img_name']\nval_label['path'] = '/kaggle/input/deepfake/phase1/valset/' + val_label['img_name']","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.281853Z","iopub.status.idle":"2024-08-15T10:53:09.282167Z","shell.execute_reply.started":"2024-08-15T10:53:09.282008Z","shell.execute_reply":"2024-08-15T10:53:09.282021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 模型训练与验证","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\nclass ProgressMeter(object):\n    def __init__(self, num_batches, *meters):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = \"\"\n\n\n    def pr2int(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print('\\t'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = '{:' + str(num_digits) + 'd}'\n        return '[' + fmt + '/' + fmt.format(num_batches) + ']'","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.284356Z","iopub.status.idle":"2024-08-15T10:53:09.284748Z","shell.execute_reply.started":"2024-08-15T10:53:09.284568Z","shell.execute_reply":"2024-08-15T10:53:09.284585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(val_loader, model, criterion):\n    batch_time = AverageMeter('Time', ':6.3f')\n    losses = AverageMeter('Loss', ':.4e')\n    top1 = AverageMeter('Acc@1', ':6.2f')\n    progress = ProgressMeter(len(val_loader), batch_time, losses, top1)\n\n    model.eval()\n    with torch.no_grad():\n        end = time.time()\n        for i, (input, target) in tqdm_notebook(enumerate(val_loader), total=len(val_loader)):\n            input = input.cuda()\n            target = target.cuda().float().unsqueeze(1)\n\n            output = model(input)\n            loss = criterion(output, target)\n\n            predicted = (output > 0.5).float()\n            acc = (predicted == target).float().mean() * 100\n            losses.update(loss.item(), input.size(0))\n            top1.update(acc, input.size(0))\n\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n        print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n        return top1.avg\n\n\n\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    batch_time = AverageMeter('Time', ':6.3f')\n    losses = AverageMeter('Loss', ':.4e')\n    top1 = AverageMeter('Acc@1', ':6.2f')\n    progress = ProgressMeter(len(train_loader), batch_time, losses, top1)\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        input = input.cuda()\n        target = target.cuda().float().unsqueeze(1)  # 调整目标形状\n\n        # compute output\n        output = model(input)\n        loss = criterion(output, target)\n\n        # measure accuracy and record loss\n        losses.update(loss.item(), input.size(0))\n\n        predicted = (output > 0.5).float()\n        acc = (predicted == target).float().mean() * 100\n        top1.update(acc, input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % 100 == 0:\n            progress.pr2int(i)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.286093Z","iopub.status.idle":"2024-08-15T10:53:09.286503Z","shell.execute_reply.started":"2024-08-15T10:53:09.286276Z","shell.execute_reply":"2024-08-15T10:53:09.286293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FFDIDataset(Dataset):\n    def __init__(self, img_path, img_label, transform=None):\n        self.img_path = img_path\n        self.img_label = img_label\n        \n        if transform is not None:\n            self.transform = transform\n        else:\n            self.transform = None\n    \n    def __getitem__(self, index):\n        img = Image.open(self.img_path[index]).convert('RGB')\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        \n        return img, torch.from_numpy(np.array(self.img_label[index]))\n    \n    def __len__(self):\n        return len(self.img_path)\n    \n# class deepfake_dataset(Dataset):\n#     def __init__(self, df, transform=None):\n#         self.df = df.reset_index(drop=True)\n#         self.transform = transform\n    \n#     def __getitem__(self, index):\n#         row = self.df.iloc[index]\n#         image = cv2.imread(row['path'])\n#         target = row['target']\n#         if self.transform is not None:\n#             data = self.transform(image=image)\n#             image = data['image'].to(torch.float32)\n\n#         target = torch.tensor(target, dtype=torch.int64)\n#         return image, target\n    \n#     def __len__(self):\n#         return len(self.df)\n    \n    \n# train_transform = A.Compose([\n#     A.Resize(height=256, width=256),\n#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n#     ToTensorV2()\n# ])\n\n# valid_transform = A.Compose([\n#     A.Resize(height=256, width=256),\n#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n#     ToTensorV2()\n# ])\n\n# train_loader = deepfake_dataset(train_label, train_transform)\n# val_loader = deepfake_dataset(val_label, train_transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.287787Z","iopub.status.idle":"2024-08-15T10:53:09.288140Z","shell.execute_reply.started":"2024-08-15T10:53:09.287959Z","shell.execute_reply":"2024-08-15T10:53:09.287972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 加载模型","metadata":{}},{"cell_type":"code","source":"import timm\nbase_model = timm.create_model('tf_efficientnet_b3.ns_jft_in1k', pretrained=True, num_classes=0)\nbase_model = base_model.cuda()\n\nepoch_num = 1\nbs_value = 32","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.290493Z","iopub.status.idle":"2024-08-15T10:53:09.291017Z","shell.execute_reply.started":"2024-08-15T10:53:09.290782Z","shell.execute_reply":"2024-08-15T10:53:09.290801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GELU_PyTorch_Tanh(nn.Module):\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh((2 / torch.pi) ** 0.5 * (x + 0.044715 * x ** 3)))\n\n# 定义CustomModel类\nclass CustomModel(nn.Module):\n    def __init__(self, base_model):\n        super(CustomModel, self).__init__()\n        self.base_model = base_model\n        \n        # 定义新的分类层\n        self.fc1 = nn.Linear(1536, 2048)  # EfficientNet-B1的输出维度是1536\n        self.bn1 = nn.BatchNorm1d(2048)\n        self.dropout1 = nn.Dropout(p=0.5)        \n        self.fc2 = nn.Linear(2048, 2048)\n        self.bn2 = nn.BatchNorm1d(2048)\n        self.gelu = GELU_PyTorch_Tanh()\n        self.dropout2 = nn.Dropout(p=0.5)\n        \n        self.final_fc = nn.Linear(2048, 1)  # 二分类问题，输出维度为1\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.base_model(x)\n        x = self.fc1(x)\n        x = self.bn1(x)\n        x = self.gelu(x)\n        x = self.dropout1(x)\n        x = self.fc2(x)\n        x = self.bn2(x)\n        x = self.gelu(x)\n        x = self.dropout2(x)\n        x = self.final_fc(x)\n        x = self.sigmoid(x)\n        return x\ncustom_model = CustomModel(base_model)\ncustom_model = custom_model.cuda()\nmodel_path = \"/kaggle/input/3112141515515/pytorch/default/1/custom_model_96.64.pt\"\nif os.path.exists(model_path):\n    custom_model.load_state_dict(torch.load(model_path))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.292569Z","iopub.status.idle":"2024-08-15T10:53:09.293004Z","shell.execute_reply.started":"2024-08-15T10:53:09.292776Z","shell.execute_reply":"2024-08-15T10:53:09.292795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(\n    FFDIDataset(train_label['path'], train_label['target'],             \n            transforms.Compose([\n                        transforms.Resize((300, 300)),\n#                         transforms.ColorJitter(brightness=.5, hue=.3),\n                        transforms.ToTensor(),\n                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    ), batch_size=bs_value, shuffle=True, num_workers=4, pin_memory=True\n)\n\nval_loader = torch.utils.data.DataLoader(\n#     FFDIDataset(val_label['path'].head(1000), val_label['target'].head(1000), \n    FFDIDataset(val_label['path'], val_label['target'], \n            transforms.Compose([\n                        transforms.Resize((300,300)),\n                        transforms.ToTensor(),\n                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    ), batch_size=bs_value, shuffle=False, num_workers=4, pin_memory=True\n)\n\ncriterion = nn.BCELoss().cuda()\noptimizer = torch.optim.Adam(custom_model.parameters(), 0.0001)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.85)\nbest_acc = 0.0\nfor epoch in range(epoch_num):\n    scheduler.step()\n    print('Epoch: ', epoch)\n\n    train(train_loader, custom_model, criterion, optimizer, epoch)\n    val_acc = validate(val_loader, custom_model, criterion)\n    val_acc = val_acc.item()  # 将 val_acc 转换为浮点数\n    if val_acc > best_acc:\n        best_acc = round(val_acc, 2)\n        torch.save(custom_model.state_dict(), f'./custom_model_{best_acc}.pt')\n\nprint(f'Best validation accuracy: {best_acc}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.294571Z","iopub.status.idle":"2024-08-15T10:53:09.294914Z","shell.execute_reply.started":"2024-08-15T10:53:09.294751Z","shell.execute_reply":"2024-08-15T10:53:09.294764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(test_loader, model, tta=10):\n    # switch to evaluate mode\n    model.eval()\n    \n    test_pred_tta = None\n    for _ in range(tta):\n        test_pred = []\n        with torch.no_grad():\n            for i, (input, target) in tqdm_notebook(enumerate(test_loader), total=len(test_loader)):\n                input = input.cuda()\n                target = target.cuda()\n\n                # compute output\n                output = model(input)\n                output = output.data.cpu().numpy()\n\n                test_pred.append(output)\n        test_pred = np.vstack(test_pred)\n    \n        if test_pred_tta is None:\n            test_pred_tta = test_pred\n        else:\n            test_pred_tta += test_pred\n    \n    # Average the predictions if TTA is used\n    test_pred_tta /= tta\n    \n    # Apply threshold to get binary predictions\n    #test_pred_tta = (test_pred_tta > 0.5).astype(int)\n    \n    return test_pred_tta","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.296017Z","iopub.status.idle":"2024-08-15T10:53:09.296345Z","shell.execute_reply.started":"2024-08-15T10:53:09.296178Z","shell.execute_reply":"2024-08-15T10:53:09.296192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = torch.utils.data.DataLoader(\n    FFDIDataset(val_label['path'], val_label['target'], \n            transforms.Compose([\n                        transforms.Resize((300, 300)),\n                        transforms.ToTensor(),\n                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    ), batch_size=bs_value, shuffle=False, num_workers=4, pin_memory=True\n)\n\nval_label['y_pred'] = predict(test_loader, custom_model, tta=1)[:, 0]  \nval_label[['img_name', 'y_pred']].to_csv('submission.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T10:53:09.297525Z","iopub.status.idle":"2024-08-15T10:53:09.297876Z","shell.execute_reply.started":"2024-08-15T10:53:09.297709Z","shell.execute_reply":"2024-08-15T10:53:09.297723Z"},"trusted":true},"execution_count":null,"outputs":[]}]}